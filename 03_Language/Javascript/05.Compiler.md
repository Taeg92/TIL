# Compiler

​      

   

#### Goal

- [x] **Lexer에 대해 정리하기.**
- [x] **Tokenizer에 대해 정리하기.**
- [x] **Parser에 대해 정리하기.**

   

   

  

## I. Lexer

> 어휘 분석의 역할을 하고 있는 Lexer에 대해 알아보자.

   

   

### 1. Lexer란?

  

**어휘 분석의 역할 담당**

Lexer는 텍스트를 받아서 한 글자 한 글자 읽어나가다가 의미를 가진 단어를 만나면 lexer에서는 그 단어를 전체 텍스트로부터 잘라서 token이란 것으로 만든다.

​     

![](https://miro.medium.com/max/700/1*fqn_MY_hFnM_CyHOZgG7gg.png)

 

   

## II. Parser

   

### 1. Parser란?

  

> *A parser is a software component that* **takes input data (frequently text) and builds a data structure** *— often some kind of parse tree, abstract syntax tree or other hierarchical structure — giving a structural representation of the input, checking for correct syntax in the process.* -[Wikipedia](https://en.wikipedia.org/wiki/Parsing)

​     

Parser는 **input 데이터를 가지고 그것을 구조적으로 나타낼 수 있게 해줍니다**. 또한 **데이터를 구조적으로 바꾸는 과정에서 주어진 input 데이터가 올바른지 검증**

   

```js
> var input = '{"msg": "hello, world"}';
> var output = JSON.parse(input);
> output
> { msg: 'hello, world' }
> output.msg
'hello, world'
```



 `input`으로 ‘{“msg”: “hello, world”}’ string이 주어지고 `input` 을 `JSON.parse` 뒤에 숨겨져있는 parser에게 넘겨주면 `output` 으로 key, value 형식으로 값을 참조할 수 있는 object로 바꿔줍니다. 



그런데 이때 다음과 같은 `input` 을 넘겨주면 어떻게 될까요?

```js
var input = '{"msg": "hello, world"';
```

   

주어진 `input` 은 완전한 object를 만들지 못하는 string이고 이것을 parser에게 넘겨주면 다음과 같은 일이 벌어집니다.

```
Uncaught SyntaxError: Unexpected end of JSON input
> output
undefined
```

 

parser는 자신에게 주어진 input 데이터를 구조적으로 나타낼 수 있게 바꾸면서 동시에 input 데이터가 올바른지도 검증하는 역할을 한다.

그래서 보통 parser가 하는 일을 **syntax anlysis **라고 한다.

  

![](https://miro.medium.com/max/700/1*cq79_EHtHh7MgGEwNXz-wQ.png)

  

## III. Tokenizer

  

### 1. Tokenizer란?

**단어를 분리하는 작업**

특정 기준, 공백이나 특수문자와 같은 것들을 기준으로 토큰을 분리하는 작업이다.

​       



### 2. Token이란?

  

**Lexer가 하는 일이 글자들을 모아서 단어를 만드는 것**이라면 그 단어를 구**조적으로 표현할 수 있게 도와주는 구조체**가 토큰이다.

   

```js
const Token = {
    type: TokenType,
    value: TokenValue,
    ...
}
```

​     